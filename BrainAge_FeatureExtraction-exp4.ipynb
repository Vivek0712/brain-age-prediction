{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d3c4b642",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fc2d9b8f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting mne\n",
      "  Downloading mne-1.2.2-py3-none-any.whl (7.6 MB)\n",
      "\u001b[K     |████████████████████████████████| 7.6 MB 3.5 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting pooch>=1.5\n",
      "  Downloading pooch-1.6.0-py3-none-any.whl (56 kB)\n",
      "\u001b[K     |████████████████████████████████| 56 kB 2.8 MB/s  eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: scipy>=1.1.0 in /anaconda/envs/azureml_py38/lib/python3.8/site-packages (from mne) (1.5.3)\n",
      "Requirement already satisfied: decorator in /anaconda/envs/azureml_py38/lib/python3.8/site-packages (from mne) (5.1.1)\n",
      "Requirement already satisfied: packaging in /anaconda/envs/azureml_py38/lib/python3.8/site-packages (from mne) (21.3)\n",
      "Requirement already satisfied: tqdm in /anaconda/envs/azureml_py38/lib/python3.8/site-packages (from mne) (4.64.1)\n",
      "Requirement already satisfied: numpy>=1.15.4 in /anaconda/envs/azureml_py38/lib/python3.8/site-packages (from mne) (1.21.6)\n",
      "Requirement already satisfied: jinja2 in /anaconda/envs/azureml_py38/lib/python3.8/site-packages (from mne) (2.11.2)\n",
      "Requirement already satisfied: matplotlib in /anaconda/envs/azureml_py38/lib/python3.8/site-packages (from mne) (3.2.1)\n",
      "Collecting appdirs>=1.3.0\n",
      "  Downloading appdirs-1.4.4-py2.py3-none-any.whl (9.6 kB)\n",
      "Requirement already satisfied: requests>=2.19.0 in /anaconda/envs/azureml_py38/lib/python3.8/site-packages (from pooch>=1.5->mne) (2.28.1)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /anaconda/envs/azureml_py38/lib/python3.8/site-packages (from packaging->mne) (3.0.9)\n",
      "Requirement already satisfied: MarkupSafe>=0.23 in /anaconda/envs/azureml_py38/lib/python3.8/site-packages (from jinja2->mne) (2.0.1)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /anaconda/envs/azureml_py38/lib/python3.8/site-packages (from matplotlib->mne) (1.4.4)\n",
      "Requirement already satisfied: python-dateutil>=2.1 in /anaconda/envs/azureml_py38/lib/python3.8/site-packages (from matplotlib->mne) (2.8.2)\n",
      "Requirement already satisfied: cycler>=0.10 in /anaconda/envs/azureml_py38/lib/python3.8/site-packages (from matplotlib->mne) (0.11.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /anaconda/envs/azureml_py38/lib/python3.8/site-packages (from requests>=2.19.0->pooch>=1.5->mne) (3.4)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in /anaconda/envs/azureml_py38/lib/python3.8/site-packages (from requests>=2.19.0->pooch>=1.5->mne) (2.1.1)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /anaconda/envs/azureml_py38/lib/python3.8/site-packages (from requests>=2.19.0->pooch>=1.5->mne) (1.26.12)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /anaconda/envs/azureml_py38/lib/python3.8/site-packages (from requests>=2.19.0->pooch>=1.5->mne) (2022.9.24)\n",
      "Requirement already satisfied: six>=1.5 in /anaconda/envs/azureml_py38/lib/python3.8/site-packages (from python-dateutil>=2.1->matplotlib->mne) (1.16.0)\n",
      "Installing collected packages: appdirs, pooch, mne\n",
      "Successfully installed appdirs-1.4.4 mne-1.2.2 pooch-1.6.0\n",
      "Collecting tsfel\n",
      "  Downloading tsfel-0.1.4-py3-none-any.whl (46 kB)\n",
      "\u001b[K     |████████████████████████████████| 46 kB 959 kB/s eta 0:00:01\n",
      "\u001b[?25hCollecting gspread>=3.1.0\n",
      "  Downloading gspread-5.7.1-py3-none-any.whl (40 kB)\n",
      "\u001b[K     |████████████████████████████████| 40 kB 2.6 MB/s  eta 0:00:01\n",
      "\u001b[?25hCollecting Sphinx>=1.8.5\n",
      "  Downloading sphinx-5.3.0-py3-none-any.whl (3.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 3.2 MB 7.3 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: scipy>=1.5.1 in /anaconda/envs/azureml_py38/lib/python3.8/site-packages (from tsfel) (1.5.3)\n",
      "Collecting oauth2client>=4.1.3\n",
      "  Downloading oauth2client-4.1.3-py2.py3-none-any.whl (98 kB)\n",
      "\u001b[K     |████████████████████████████████| 98 kB 4.5 MB/s  eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: pandas>=0.25.3 in /anaconda/envs/azureml_py38/lib/python3.8/site-packages (from tsfel) (1.1.5)\n",
      "Requirement already satisfied: numpy>=1.18.5 in /anaconda/envs/azureml_py38/lib/python3.8/site-packages (from tsfel) (1.21.6)\n",
      "Requirement already satisfied: setuptools>=47.1.1 in /anaconda/envs/azureml_py38/lib/python3.8/site-packages (from tsfel) (49.6.0)\n",
      "Requirement already satisfied: ipython>=7.4.0 in /anaconda/envs/azureml_py38/lib/python3.8/site-packages (from tsfel) (8.5.0)\n",
      "Requirement already satisfied: google-auth-oauthlib>=0.4.1 in /anaconda/envs/azureml_py38/lib/python3.8/site-packages (from gspread>=3.1.0->tsfel) (0.4.6)\n",
      "Requirement already satisfied: google-auth>=1.12.0 in /anaconda/envs/azureml_py38/lib/python3.8/site-packages (from gspread>=3.1.0->tsfel) (2.13.0)\n",
      "Collecting sphinxcontrib-serializinghtml>=1.1.5\n",
      "  Downloading sphinxcontrib_serializinghtml-1.1.5-py2.py3-none-any.whl (94 kB)\n",
      "\u001b[K     |████████████████████████████████| 94 kB 1.2 MB/s  eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: packaging>=21.0 in /anaconda/envs/azureml_py38/lib/python3.8/site-packages (from Sphinx>=1.8.5->tsfel) (21.3)\n",
      "Collecting sphinxcontrib-devhelp\n",
      "  Downloading sphinxcontrib_devhelp-1.0.2-py2.py3-none-any.whl (84 kB)\n",
      "\u001b[K     |████████████████████████████████| 84 kB 2.0 MB/s  eta 0:00:01\n",
      "\u001b[?25hCollecting alabaster<0.8,>=0.7\n",
      "  Downloading alabaster-0.7.12-py2.py3-none-any.whl (14 kB)\n",
      "Requirement already satisfied: Pygments>=2.12 in /anaconda/envs/azureml_py38/lib/python3.8/site-packages (from Sphinx>=1.8.5->tsfel) (2.13.0)\n",
      "Collecting imagesize>=1.3\n",
      "  Downloading imagesize-1.4.1-py2.py3-none-any.whl (8.8 kB)\n",
      "Collecting sphinxcontrib-applehelp\n",
      "  Downloading sphinxcontrib_applehelp-1.0.2-py2.py3-none-any.whl (121 kB)\n",
      "\u001b[K     |████████████████████████████████| 121 kB 90.6 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting Jinja2>=3.0\n",
      "  Downloading Jinja2-3.1.2-py3-none-any.whl (133 kB)\n",
      "\u001b[K     |████████████████████████████████| 133 kB 79.4 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: importlib-metadata>=4.8; python_version < \"3.10\" in /anaconda/envs/azureml_py38/lib/python3.8/site-packages (from Sphinx>=1.8.5->tsfel) (4.13.0)\n",
      "Collecting sphinxcontrib-jsmath\n",
      "  Downloading sphinxcontrib_jsmath-1.0.1-py2.py3-none-any.whl (5.1 kB)\n",
      "Collecting sphinxcontrib-qthelp\n",
      "  Downloading sphinxcontrib_qthelp-1.0.3-py2.py3-none-any.whl (90 kB)\n",
      "\u001b[K     |████████████████████████████████| 90 kB 4.1 MB/s  eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: requests>=2.5.0 in /anaconda/envs/azureml_py38/lib/python3.8/site-packages (from Sphinx>=1.8.5->tsfel) (2.28.1)\n",
      "Collecting sphinxcontrib-htmlhelp>=2.0.0\n",
      "  Downloading sphinxcontrib_htmlhelp-2.0.0-py2.py3-none-any.whl (100 kB)\n",
      "\u001b[K     |████████████████████████████████| 100 kB 5.6 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: babel>=2.9 in /anaconda/envs/azureml_py38/lib/python3.8/site-packages (from Sphinx>=1.8.5->tsfel) (2.11.0)\n",
      "Requirement already satisfied: snowballstemmer>=2.0 in /anaconda/envs/azureml_py38/lib/python3.8/site-packages (from Sphinx>=1.8.5->tsfel) (2.2.0)\n",
      "Collecting docutils<0.20,>=0.14\n",
      "  Downloading docutils-0.19-py3-none-any.whl (570 kB)\n",
      "\u001b[K     |████████████████████████████████| 570 kB 76.8 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: pyasn1>=0.1.7 in /anaconda/envs/azureml_py38/lib/python3.8/site-packages (from oauth2client>=4.1.3->tsfel) (0.4.8)\n",
      "Collecting httplib2>=0.9.1\n",
      "  Downloading httplib2-0.21.0-py3-none-any.whl (96 kB)\n",
      "\u001b[K     |████████████████████████████████| 96 kB 3.6 MB/s  eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: six>=1.6.1 in /anaconda/envs/azureml_py38/lib/python3.8/site-packages (from oauth2client>=4.1.3->tsfel) (1.16.0)\n",
      "Requirement already satisfied: pyasn1-modules>=0.0.5 in /anaconda/envs/azureml_py38/lib/python3.8/site-packages (from oauth2client>=4.1.3->tsfel) (0.2.8)\n",
      "Requirement already satisfied: rsa>=3.1.4 in /anaconda/envs/azureml_py38/lib/python3.8/site-packages (from oauth2client>=4.1.3->tsfel) (4.9)\n",
      "Requirement already satisfied: pytz>=2017.2 in /anaconda/envs/azureml_py38/lib/python3.8/site-packages (from pandas>=0.25.3->tsfel) (2022.5)\n",
      "Requirement already satisfied: python-dateutil>=2.7.3 in /anaconda/envs/azureml_py38/lib/python3.8/site-packages (from pandas>=0.25.3->tsfel) (2.8.2)\n",
      "Requirement already satisfied: matplotlib-inline in /anaconda/envs/azureml_py38/lib/python3.8/site-packages (from ipython>=7.4.0->tsfel) (0.1.6)\n",
      "Requirement already satisfied: prompt-toolkit<3.1.0,>3.0.1 in /anaconda/envs/azureml_py38/lib/python3.8/site-packages (from ipython>=7.4.0->tsfel) (3.0.28)\n",
      "Requirement already satisfied: pexpect>4.3; sys_platform != \"win32\" in /anaconda/envs/azureml_py38/lib/python3.8/site-packages (from ipython>=7.4.0->tsfel) (4.8.0)\n",
      "Requirement already satisfied: stack-data in /anaconda/envs/azureml_py38/lib/python3.8/site-packages (from ipython>=7.4.0->tsfel) (0.5.1)\n",
      "Requirement already satisfied: pickleshare in /anaconda/envs/azureml_py38/lib/python3.8/site-packages (from ipython>=7.4.0->tsfel) (0.7.5)\n",
      "Requirement already satisfied: backcall in /anaconda/envs/azureml_py38/lib/python3.8/site-packages (from ipython>=7.4.0->tsfel) (0.2.0)\n",
      "Requirement already satisfied: traitlets>=5 in /anaconda/envs/azureml_py38/lib/python3.8/site-packages (from ipython>=7.4.0->tsfel) (5.5.0)\n",
      "Requirement already satisfied: decorator in /anaconda/envs/azureml_py38/lib/python3.8/site-packages (from ipython>=7.4.0->tsfel) (5.1.1)\n",
      "Requirement already satisfied: jedi>=0.16 in /anaconda/envs/azureml_py38/lib/python3.8/site-packages (from ipython>=7.4.0->tsfel) (0.18.0)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in /anaconda/envs/azureml_py38/lib/python3.8/site-packages (from google-auth-oauthlib>=0.4.1->gspread>=3.1.0->tsfel) (1.3.1)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /anaconda/envs/azureml_py38/lib/python3.8/site-packages (from google-auth>=1.12.0->gspread>=3.1.0->tsfel) (5.2.0)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /anaconda/envs/azureml_py38/lib/python3.8/site-packages (from packaging>=21.0->Sphinx>=1.8.5->tsfel) (3.0.9)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /anaconda/envs/azureml_py38/lib/python3.8/site-packages (from Jinja2>=3.0->Sphinx>=1.8.5->tsfel) (2.0.1)\n",
      "Requirement already satisfied: zipp>=0.5 in /anaconda/envs/azureml_py38/lib/python3.8/site-packages (from importlib-metadata>=4.8; python_version < \"3.10\"->Sphinx>=1.8.5->tsfel) (3.9.0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /anaconda/envs/azureml_py38/lib/python3.8/site-packages (from requests>=2.5.0->Sphinx>=1.8.5->tsfel) (1.26.12)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in /anaconda/envs/azureml_py38/lib/python3.8/site-packages (from requests>=2.5.0->Sphinx>=1.8.5->tsfel) (2.1.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /anaconda/envs/azureml_py38/lib/python3.8/site-packages (from requests>=2.5.0->Sphinx>=1.8.5->tsfel) (3.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /anaconda/envs/azureml_py38/lib/python3.8/site-packages (from requests>=2.5.0->Sphinx>=1.8.5->tsfel) (2022.9.24)\n",
      "Requirement already satisfied: wcwidth in /anaconda/envs/azureml_py38/lib/python3.8/site-packages (from prompt-toolkit<3.1.0,>3.0.1->ipython>=7.4.0->tsfel) (0.2.5)\n",
      "Requirement already satisfied: ptyprocess>=0.5 in /anaconda/envs/azureml_py38/lib/python3.8/site-packages (from pexpect>4.3; sys_platform != \"win32\"->ipython>=7.4.0->tsfel) (0.7.0)\n",
      "Requirement already satisfied: asttokens in /anaconda/envs/azureml_py38/lib/python3.8/site-packages (from stack-data->ipython>=7.4.0->tsfel) (2.0.8)\n",
      "Requirement already satisfied: executing in /anaconda/envs/azureml_py38/lib/python3.8/site-packages (from stack-data->ipython>=7.4.0->tsfel) (1.1.1)\n",
      "Requirement already satisfied: pure-eval in /anaconda/envs/azureml_py38/lib/python3.8/site-packages (from stack-data->ipython>=7.4.0->tsfel) (0.2.2)\n",
      "Requirement already satisfied: parso<0.9.0,>=0.8.0 in /anaconda/envs/azureml_py38/lib/python3.8/site-packages (from jedi>=0.16->ipython>=7.4.0->tsfel) (0.8.3)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in /anaconda/envs/azureml_py38/lib/python3.8/site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib>=0.4.1->gspread>=3.1.0->tsfel) (3.2.2)\n",
      "\u001b[31mERROR: pyldavis 3.3.1 requires sklearn, which is not installed.\u001b[0m\n",
      "\u001b[31mERROR: pyldavis 3.3.1 has requirement pandas>=1.2.0, but you'll have pandas 1.1.5 which is incompatible.\u001b[0m\n",
      "\u001b[31mERROR: pycaret 2.3.10 has requirement numba<0.55, but you'll have numba 0.55.2 which is incompatible.\u001b[0m\n",
      "\u001b[31mERROR: pycaret 2.3.10 has requirement pyyaml<6.0.0, but you'll have pyyaml 6.0 which is incompatible.\u001b[0m\n",
      "\u001b[31mERROR: pycaret 2.3.10 has requirement scikit-learn==0.23.2, but you'll have scikit-learn 0.22.1 which is incompatible.\u001b[0m\n",
      "\u001b[31mERROR: pandas-profiling 3.4.0 has requirement statsmodels<0.14,>=0.13.2, but you'll have statsmodels 0.11.0 which is incompatible.\u001b[0m\n",
      "\u001b[31mERROR: azureml-widgets 1.47.0 has requirement jinja2<=2.11.2, but you'll have jinja2 3.1.2 which is incompatible.\u001b[0m\n",
      "\u001b[31mERROR: azureml-train-automl-runtime 1.47.0 has requirement jinja2<=2.11.2, but you'll have jinja2 3.1.2 which is incompatible.\u001b[0m\n",
      "\u001b[31mERROR: azureml-inference-server-http 0.7.6 has requirement flask<2.2.0, but you'll have flask 2.2.2 which is incompatible.\u001b[0m\n",
      "\u001b[31mERROR: azureml-contrib-notebook 1.47.0 has requirement nbconvert<6, but you'll have nbconvert 7.2.4 which is incompatible.\u001b[0m\n",
      "Installing collected packages: gspread, sphinxcontrib-serializinghtml, sphinxcontrib-devhelp, alabaster, imagesize, sphinxcontrib-applehelp, Jinja2, sphinxcontrib-jsmath, sphinxcontrib-qthelp, sphinxcontrib-htmlhelp, docutils, Sphinx, httplib2, oauth2client, tsfel\n",
      "  Attempting uninstall: Jinja2\n",
      "    Found existing installation: Jinja2 2.11.2\n",
      "    Uninstalling Jinja2-2.11.2:\n",
      "      Successfully uninstalled Jinja2-2.11.2\n",
      "Successfully installed Jinja2-3.1.2 Sphinx-5.3.0 alabaster-0.7.12 docutils-0.19 gspread-5.7.1 httplib2-0.21.0 imagesize-1.4.1 oauth2client-4.1.3 sphinxcontrib-applehelp-1.0.2 sphinxcontrib-devhelp-1.0.2 sphinxcontrib-htmlhelp-2.0.0 sphinxcontrib-jsmath-1.0.1 sphinxcontrib-qthelp-1.0.3 sphinxcontrib-serializinghtml-1.1.5 tsfel-0.1.4\n"
     ]
    }
   ],
   "source": [
    "!pip3 install mne\n",
    "!pip3 install tsfel\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import mne\n",
    "import os\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tqdm.auto import tqdm\n",
    "from joblib import Parallel, delayed\n",
    "import gc\n",
    "import json\n",
    "from tsfel import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a0e88c5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_path = \"Data/training\"\n",
    "\n",
    "#test_path = \"Data/test_phase1\"\n",
    "\n",
    "test_path = \"Data/test_phase2\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5d11bf89",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Saving additional information that might be required while making predictions \n",
    "feature_extraction_info = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "48f0cf8d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data subjects\n",
      "\n",
      "0          1\n",
      "1          2\n",
      "2          3\n",
      "3          4\n",
      "4          5\n",
      "        ... \n",
      "1195    1196\n",
      "1196    1197\n",
      "1197    1198\n",
      "1198    1199\n",
      "1199    1200\n",
      "Length: 1200, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "train_files = os.listdir(train_path)\n",
    "train_subjects = [int(file[4:8]) for file in train_files if \"EC_raw\" in file]\n",
    "\n",
    "feature_extraction_info['training_dataset_subjects'] = train_subjects\n",
    "\n",
    "print(\"Training data subjects\\n\")\n",
    "print(pd.Series(train_subjects))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fa35faa2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test data subjects\n",
      "\n",
      "0      1601\n",
      "1      1602\n",
      "2      1603\n",
      "3      1604\n",
      "4      1605\n",
      "       ... \n",
      "395    1996\n",
      "396    1997\n",
      "397    1998\n",
      "398    1999\n",
      "399    2000\n",
      "Length: 400, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "test_files = os.listdir(test_path)\n",
    "test_subjects = [int(file[4:8]) for file in test_files if \"EC_raw\" in file]\n",
    "\n",
    "n_subjects_test = len(test_subjects)\n",
    "\n",
    "feature_extraction_info['test_dataset_subjects'] = test_subjects\n",
    "feature_extraction_info['n_subjects_test'] = n_subjects_test\n",
    "\n",
    "print(\"Test data subjects\\n\")\n",
    "print(pd.Series(test_subjects))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99c6c827",
   "metadata": {},
   "source": [
    "# Processing Params"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbf26ccc",
   "metadata": {},
   "source": [
    "### Cropping data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1f786474",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Eyes closed - roughly 40 secs data available for all subjects\n",
    "EC_crop_start = 1 #secs\n",
    "EC_crop_end = 39 #secs\n",
    "\n",
    "#Eyes open - roughly 20 secs data available for all subjects\n",
    "EO_crop_start = 1 #secs\n",
    "EO_crop_end = 19 #secs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b895aeae",
   "metadata": {},
   "source": [
    "### Resampling and filtering params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "935a4331",
   "metadata": {},
   "outputs": [],
   "source": [
    "#All data will be resampled at this rate\n",
    "new_sRate = 250 #Hz\n",
    "\n",
    "#Notch filter\n",
    "notch_freqz = [60.0, 120.0] #Hz\n",
    "\n",
    "#Bandpass filter \n",
    "band_low = 1 #Hz\n",
    "band_high = 100 #Hz"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db5ad2a7",
   "metadata": {},
   "source": [
    "### Augmentation params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a7ac5597",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Window size in secs\n",
    "sample_duration = 6 \n",
    "\n",
    "#window jump size secs\n",
    "jump_duration = 4 \n",
    "\n",
    "sample_size = int(new_sRate*sample_duration)\n",
    "jump_size = int(new_sRate*jump_duration)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74b73943",
   "metadata": {},
   "source": [
    "### Data split params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "106972b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#For train-test-split\n",
    "test_size = 0.15"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "446e9995",
   "metadata": {},
   "source": [
    "# Loading Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f3694deb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_n_process(path, condition, subject):\n",
    "    \"\"\"\n",
    "    Loads data into a mne-raw object, from a file pertaining to a subject under a condition.\n",
    "    \n",
    "    Then following operations are performed on the raw object:\n",
    "        1) Resampling\n",
    "        2) Notch filtering\n",
    "        3) IIR bandpass filtering\n",
    "        \n",
    "    Then data is cropped between two points in time.\n",
    "    \n",
    "    Returns the data back as a 2d array\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    fname = f\"subj{subject:04}_\" + condition +\"_raw.fif.gz\"\n",
    "    raw = mne.io.read_raw(os.path.join(path,fname), preload=True, verbose=0)\n",
    "    raw.resample(new_sRate)\n",
    "    raw = raw.notch_filter(notch_freqz, verbose='WARNING')\n",
    "    raw = raw.filter(l_freq=band_low, h_freq=band_high, method=\"iir\", n_jobs=-1, verbose='WARNING')\n",
    "    if condition == \"EO\":\n",
    "        raw = raw.crop(tmin=EO_crop_start, tmax=EO_crop_end)\n",
    "    elif condition == \"EC\":\n",
    "        raw = raw.crop(tmin=EC_crop_start, tmax=EC_crop_end)\n",
    "    else:\n",
    "        print(\"Not a valid condition\")\n",
    "    raw = raw.get_data()\n",
    "    return raw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6c693a58",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_dataset(path, condition, subjects):\n",
    "    \n",
    "    \"\"\"\n",
    "    Loads and processes data from files pertaining to subjects under a condition.\n",
    "    \n",
    "    All files must exist in the path provided as argument\n",
    "    \n",
    "    Returns the data in the form of a 3d array\n",
    "    \n",
    "    \"\"\"\n",
    "\n",
    "    dataset = Parallel(n_jobs=-1)(delayed(load_n_process)(path, condition, s) for s in tqdm(subjects))\n",
    "\n",
    "    dataset = np.array(dataset)\n",
    "\n",
    "    dataset = dataset[:, :-1, :]\n",
    "\n",
    "    dataset = 100000*dataset\n",
    "\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38103baf",
   "metadata": {},
   "source": [
    "## Loading data of Eyes closed condition (EC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "713f26a3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6a3f9cd013ff46218446352de868ef9a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Available Training data shape for 'eyes closed' condition: (1200, 128, 9501)\n"
     ]
    }
   ],
   "source": [
    "train_ec = load_dataset(train_path, \"EC\", train_subjects)\n",
    "\n",
    "print(f\"Available Training data shape for 'eyes closed' condition: {train_ec.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0c85762a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e80be04cb65948e7911289f8324e60f0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/400 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Avaialable Test data shape for 'eyes closed' condition: (400, 128, 9501)\n"
     ]
    }
   ],
   "source": [
    "test_ec = load_dataset(test_path, \"EC\", test_subjects)\n",
    "\n",
    "print(f\"Avaialable Test data shape for 'eyes closed' condition: {test_ec.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "098c1d58",
   "metadata": {},
   "source": [
    "## Loading data of Eyes open condition (EO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9d26a7f2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "27def68bf8f34542a9602af87424478e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Available Training data shape for 'eyes open' condition: (1200, 128, 4501)\n"
     ]
    }
   ],
   "source": [
    "train_eo = load_dataset(train_path, \"EO\", train_subjects)\n",
    "\n",
    "print(f\"Available Training data shape for 'eyes open' condition: {train_eo.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "716e49aa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d0738690610e46488f743977a283b643",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/400 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Available Test data shape for 'eyes open' condition: (400, 128, 4501)\n"
     ]
    }
   ],
   "source": [
    "test_eo = load_dataset(test_path, \"EO\", test_subjects)\n",
    "\n",
    "print(f\"Available Test data shape for 'eyes open' condition: {test_eo.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8dbc19b1",
   "metadata": {},
   "source": [
    "## Loading target values of training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9751f2a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        id        age\n",
      "0        1   8.581679\n",
      "1        2  17.324321\n",
      "2        3  11.059890\n",
      "3        4   6.027720\n",
      "4        5  11.306297\n",
      "...    ...        ...\n",
      "1195  1196   7.979237\n",
      "1196  1197   9.107232\n",
      "1197  1198  14.886835\n",
      "1198  1199   9.102213\n",
      "1199  1200   6.003080\n",
      "\n",
      "[1200 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "df_train_ages = pd.read_csv(os.path.join(train_path, \"train_subjects.csv\"), index_col=None)\n",
    "train_ages = df_train_ages['age'].to_numpy()\n",
    "\n",
    "print(df_train_ages[[\"id\", \"age\"]])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85b15896",
   "metadata": {},
   "source": [
    "# Train-Test split"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2510b97c",
   "metadata": {},
   "source": [
    "### Split of EC condition data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8dfd6533",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data shape for EC condition after train-test split:  (1020, 128, 9501)\n",
      "Validation data shape for EC condition  after train_test split:  (180, 128, 9501)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "2533"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_ec, X_valid_ec, Y_train_ec, Y_valid_ec = train_test_split(train_ec, train_ages, test_size=test_size, random_state=999)\n",
    "\n",
    "print(\"Training data shape for EC condition after train-test split: \", X_train_ec.shape)\n",
    "print(\"Validation data shape for EC condition  after train_test split: \", X_valid_ec.shape)\n",
    "\n",
    "del(train_ec)\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c998df25",
   "metadata": {},
   "source": [
    "### Split of EO condition data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5afc2e9a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data shape for EO condition after train-test split:  (1020, 128, 4501)\n",
      "Validation data shape for EO condition after train-test split:  (180, 128, 4501)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "21"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_eo, X_valid_eo, Y_train_eo, Y_valid_eo = train_test_split(train_eo, train_ages, test_size=test_size, random_state=999)\n",
    "\n",
    "print(\"Training data shape for EO condition after train-test split: \", X_train_eo.shape)\n",
    "print(\"Validation data shape for EO condition after train-test split: \", X_valid_eo.shape)\n",
    "\n",
    "del(train_eo)\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "6bf97f9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Number of subjects used for training (equal for X_train_ec and X_train_eo)\n",
    "n_subjects_train = X_train_ec.shape[0]\n",
    "\n",
    "#Number of subjects used for validation (equal for X_train_ec and X_train_eo)\n",
    "n_subjects_valid = X_valid_ec.shape[0] \n",
    "\n",
    "#Number of channels (same for all training and validation arrays)\n",
    "n_channels = X_train_ec.shape[1] \n",
    "\n",
    "feature_extraction_info[\"n_subjects_train\"] = n_subjects_train\n",
    "feature_extraction_info[\"n_subjects_valid\"] = n_subjects_valid\n",
    "feature_extraction_info[\"n_channels\"] = n_channels"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "036ab127",
   "metadata": {},
   "source": [
    "# Data Augmentation with sliding window "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc693d2b",
   "metadata": {},
   "source": [
    "A sliding window is used to create more samples for training and validation.\n",
    "    \n",
    "A window of size of length 'sample_size' is slid, with a jump length of 'jump_size', over \n",
    "the entire available epoch of a subject's data, so as to extract more samples from it.\n",
    "\n",
    "The jump size decides the amount of overlap between any two consecutive extracted samples.\n",
    "\n",
    "Augmentation of training dataset increases the number of training samples data, which helps models fit more robustly.\n",
    "\n",
    "Augmentation of test dataset increases the number of sub-predictions that can be made over a single subjects data, and averaging over those sub-predictions increases the robustness of that subject's prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ead56d6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def augment_training_samples(X, Y):\n",
    "    \n",
    "    \"\"\"\n",
    "   Inputs:\n",
    "   1) X - Data array of shape (n_subjects, n_channels, cropped_epoch_length)\n",
    "   2) Y - Data array of shape (n_subjects,)\n",
    "   \n",
    "   Returns:\n",
    "   1) X_aug - Data array of shape (n_samples, n_channels, sample_size)\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    X_aug = []\n",
    "    Y_aug = []\n",
    "\n",
    "    m = X.shape[-1]\n",
    "\n",
    "    for s in range(X.shape[0]):\n",
    "        k = 0\n",
    "        while (k <= m-1-sample_size):\n",
    "            X_aug.append(X[s,:,k:k+sample_size])\n",
    "            Y_aug.append(Y[s])\n",
    "            k += jump_size\n",
    "\n",
    "    X_aug = np.array(X_aug)\n",
    "    Y_aug = np.array(Y_aug)\n",
    "\n",
    "    return X_aug, Y_aug"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c6264652",
   "metadata": {},
   "outputs": [],
   "source": [
    "def augment_test_samples(X):\n",
    "    \n",
    "    \"\"\"\n",
    "   Inputs:\n",
    "   1) X - Data array of shape (n_subjects, n_channels, cropped_epoch_length)\n",
    "   \n",
    "   Returns:\n",
    "   1) X_aug - Data array of shape (n_samples, n_channels, sample_size)\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    X_aug = []\n",
    "\n",
    "    m = X.shape[-1]\n",
    "\n",
    "    for s in range(X.shape[0]):\n",
    "        k = 0\n",
    "        while (k <= m-1-sample_size):\n",
    "            X_aug.append(X[s,:,k:k+sample_size])\n",
    "            k += jump_size\n",
    "\n",
    "    X_aug = np.array(X_aug)\n",
    "\n",
    "    return X_aug"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec28b94c",
   "metadata": {},
   "source": [
    "### Augmentation of EC condition data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c7187617",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Augmented training data shape for EC condition:  (9180, 128, 1500)\n",
      "Augmented training target shape for EC condition:  (9180,)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "84"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_ec_aug, Y_train_ec_aug = augment_training_samples(X_train_ec, Y_train_ec)\n",
    "\n",
    "print(\"Augmented training data shape for EC condition: \", X_train_ec_aug.shape)\n",
    "print(\"Augmented training target shape for EC condition: \", Y_train_ec_aug.shape)\n",
    "\n",
    "del(X_train_ec)\n",
    "del(Y_train_ec)\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "ae9a8d75",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Augmented validation data shape for EC condition:  (1620, 128, 1500)\n",
      "Augmented validation target shape for EC condition:  (1620,)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "21"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_valid_ec_aug, Y_valid_ec_aug = augment_training_samples(X_valid_ec, Y_valid_ec)\n",
    "\n",
    "print(\"Augmented validation data shape for EC condition: \", X_valid_ec_aug.shape)\n",
    "print(\"Augmented validation target shape for EC condition: \", Y_valid_ec_aug.shape)\n",
    "\n",
    "del(X_valid_ec)\n",
    "del(Y_valid_ec)\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "9135e36a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Augmented X_test data shape for EC condition:  (3600, 128, 1500)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "21"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test_ec_aug = augment_test_samples(test_ec)\n",
    "\n",
    "print(\"Augmented X_test data shape for EC condition: \", X_test_ec_aug.shape)\n",
    "\n",
    "del(test_ec)\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "1631fe8a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of data samples extracted from each Subject's EC data:  9\n"
     ]
    }
   ],
   "source": [
    "n_windows_ec = int(X_test_ec_aug.shape[0]/n_subjects_test)\n",
    "feature_extraction_info['n_windows_ec'] = n_windows_ec\n",
    "\n",
    "print(\"Number of data samples extracted from each Subject's EC data: \", n_windows_ec)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "550b0dc3",
   "metadata": {},
   "source": [
    "### Augmentation of EO condition data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "9883bf90",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Augmented training data shape for EO condition:  (4080, 128, 1500)\n",
      "Augmented training target shape for EO condition:  (4080,)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "42"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_eo_aug, Y_train_eo_aug = augment_training_samples(X_train_eo, Y_train_eo)\n",
    "\n",
    "print(\"Augmented training data shape for EO condition: \", X_train_eo_aug.shape)\n",
    "print(\"Augmented training target shape for EO condition: \", Y_train_eo_aug.shape)\n",
    "\n",
    "del(X_train_eo)\n",
    "del(Y_train_eo)\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "98c707da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Augmented validation data shape for EO condition:  (720, 128, 1500)\n",
      "Augmented validation target shape for EO condition:  (720,)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "21"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_valid_eo_aug, Y_valid_eo_aug = augment_training_samples(X_valid_eo, Y_valid_eo)\n",
    "\n",
    "print(\"Augmented validation data shape for EO condition: \", X_valid_eo_aug.shape)\n",
    "print(\"Augmented validation target shape for EO condition: \", Y_valid_eo_aug.shape)\n",
    "\n",
    "del(X_valid_eo)\n",
    "del(Y_valid_eo)\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "dc6cb1d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Augmented test data shape for EO condition:  (1600, 128, 1500)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "21"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test_eo_aug = augment_test_samples(test_eo)\n",
    "\n",
    "print(\"Augmented test data shape for EO condition: \", X_test_eo_aug.shape)\n",
    "\n",
    "del(test_eo)\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "6d1d0e32",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of data samples extracted from each Subject's EO data:  4\n"
     ]
    }
   ],
   "source": [
    "n_windows_eo = int(X_test_eo_aug.shape[0]/n_subjects_test)\n",
    "feature_extraction_info['n_windows_eo'] = n_windows_eo\n",
    "\n",
    "print(\"Number of data samples extracted from each Subject's EO data: \", n_windows_eo)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "386b7708",
   "metadata": {},
   "source": [
    "# Feature Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "230a7060",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_Features(signal):\n",
    "    \n",
    "    \"\"\"\n",
    "    Takes a signal (1d array), and returns a 1d array containing temporal, spectral, & statistical features \n",
    "    calculated over that signal\n",
    "    \"\"\"\n",
    "    \n",
    "    signal_abs = np.abs(signal)\n",
    "    \n",
    "    features = []\n",
    "    \n",
    "    features.append(auc(signal, new_sRate))  #Computes the area under the curve of the signal computed with trapezoid rule.\n",
    "    features.append(autocorr(signal))  #Computes autocorrelation of the signal.\n",
    "    features.append(calc_centroid(signal, new_sRate)) #Computes the centroid along the time axis.\n",
    "    features.append(calc_mean(signal_abs))  #Computes mean value of the absolute values of the signal.\n",
    "    features.append(calc_median(signal_abs))  #Computes median of the absolute values of the signal.\n",
    "    features.append(calc_std(signal_abs))  #Computes standard deviation (std) of the absolute values of the signal.\n",
    "    features.append(calc_var(signal_abs))  #Computes variance of the absolute values of the signal.\n",
    "    features.append(distance(signal))  #Computes signal traveled distance.\n",
    "    features.append(fundamental_frequency(signal, new_sRate))    #Computes fundamental frequency of the signal.\n",
    "    features.append(interq_range(signal))  #Computes interquartile range of the signal.\n",
    "    features.append(kurtosis(signal))  #Computes kurtosis of the signal.\n",
    "    features.append(max_power_spectrum(signal, new_sRate))   #Computes maximum power spectrum density of the signal.\n",
    "    features.append(mean_abs_deviation(signal))    #Computes mean absolute deviation of the signal.\n",
    "    features.append(mean_abs_diff(signal))     #Computes mean absolute differences of the signal.\n",
    "    features.append(mean_diff(signal))     #Computes mean of differences of the signal.\n",
    "    features.append(median_abs_deviation(signal))  #Computes median absolute deviation of the signal.\n",
    "    features.append(median_abs_diff(signal))   #Computes median absolute differences of the signal.\n",
    "    features.append(median_diff(signal))   #Computes median of differences of the signal.\n",
    "    features.append(median_frequency(signal, new_sRate))  #Computes median frequency of the signal.\n",
    "    features.append(pk_pk_distance(signal))   #Computes the peak to peak distance.\n",
    "    features.append(rms(signal))   #Computes root mean square of the signal.\n",
    "    features.append(skewness(signal))  #Computes skewness of the signal.\n",
    "    features.append(spectral_centroid(signal, new_sRate))     #Barycenter of the spectrum.\n",
    "    features.append(spectral_decrease(signal, new_sRate))     #Represents the amount of decreasing of the spectra amplitude.\n",
    "    features.append(spectral_distance(signal, new_sRate))     #Computes the signal spectral distance.\n",
    "    features.append(spectral_kurtosis(signal, new_sRate))     #Measures the flatness of a distribution around its mean value.\n",
    "    features.append(spectral_positive_turning(signal, new_sRate))     #Computes number of positive turning points of the fft magnitude signal.\n",
    "    features.append(spectral_roll_off(signal, new_sRate))     #Computes the spectral roll-off of the signal.\n",
    "    features.append(spectral_roll_on(signal, new_sRate))  #Computes the spectral roll-on of the signal.\n",
    "    features.append(spectral_skewness(signal, new_sRate))     #Measures the asymmetry of a distribution around its mean value.\n",
    "    features.append(spectral_slope(signal, new_sRate))    #Computes the spectral slope.\n",
    "    features.append(spectral_spread(signal, new_sRate))   #Measures the spread of the spectrum around its mean value.\n",
    "    features.append(spectral_variation(signal, new_sRate))    #Computes the amount of variation of the spectrum along time.\n",
    "    features.append(sum_abs_diff(signal))  #Computes sum of absolute differences of the signal.\n",
    "    features.append(total_energy(signal, new_sRate))  #Computes the total energy of the signal.\n",
    "    \n",
    "    return np.array(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "3aa4abb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_features(X):\n",
    "    \n",
    "    \"\"\"\n",
    "    Takes in a 3d array where the features are calculated along axis-2. \n",
    "    The features are calculated for every channel for every sample.\n",
    "    The features of all channels are then flattened together for every sample.\n",
    "    \n",
    "    Input:\n",
    "    X - Data array of shape (n_samples, n_channels, sample_size)\n",
    "    \n",
    "    Returns:\n",
    "    X_features - Data array of shape (n_samples, n_features)\n",
    "    \"\"\"\n",
    "    \n",
    "    n_samples = X.shape[0]\n",
    "    \n",
    "    X = X.reshape(-1, sample_size)\n",
    "\n",
    "    X_features = Parallel(n_jobs=-1)(delayed(calc_Features)(X[s]) for s in tqdm(range(X.shape[0])))\n",
    "\n",
    "    X_features = np.array(X_features)\n",
    "\n",
    "    n_features_per_vec = X_features.shape[1]\n",
    "\n",
    "    X_features = X_features.reshape(n_samples, n_channels, n_features_per_vec)\n",
    "    \n",
    "    X_features = X_features.reshape(X_features.shape[0], -1)\n",
    "\n",
    "    return X_features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b24a8f6b",
   "metadata": {},
   "source": [
    "### Feature extraction from EC condition data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "a04dbbd2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7f4bc2b906e842bb9f0968b8bf7a9ff9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1175040 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data feature shape for EC condition:  (9180, 4480)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "4140"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_features_ec = get_features(X_train_ec_aug)\n",
    "\n",
    "print(\"Training data feature shape for EC condition: \", train_features_ec.shape)\n",
    "\n",
    "del(X_train_ec_aug)\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "dda49a79",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7611a93242bb4906aa37ee6037b47c49",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/207360 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation data feature shape for EC condition:  (1620, 4480)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "4378"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "valid_features_ec = get_features(X_valid_ec_aug)\n",
    "\n",
    "print(\"Validation data feature shape for EC condition: \", valid_features_ec.shape)\n",
    "\n",
    "del(X_valid_ec_aug)\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "fd117bbf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "71a59566f9c44fcd85f2583612746b58",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/460800 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test data feature shape for EC condition:  (3600, 4480)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "8832"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_features_ec = get_features(X_test_ec_aug)\n",
    "\n",
    "print(\"Test data feature shape for EC condition: \", test_features_ec.shape)\n",
    "\n",
    "del(X_test_ec_aug)\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb4c0f35",
   "metadata": {},
   "source": [
    "### Feature extraction from EO condition data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "4f4e517e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b66f826f232345daaeb338d38cc1a5b5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/522240 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data feature shape for EO condition:  (4080, 4480)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "10311"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_features_eo = get_features(X_train_eo_aug)\n",
    "\n",
    "print(\"Training data feature shape for EO condition: \", train_features_eo.shape)\n",
    "\n",
    "del(X_train_eo_aug)\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "976be2a7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2f656994e31f4188a347b0bde81be901",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/92160 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation data feature shape for EO condition:  (720, 4480)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "4157"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "valid_features_eo = get_features(X_valid_eo_aug)\n",
    "\n",
    "print(\"Validation data feature shape for EO condition: \", valid_features_eo.shape)\n",
    "\n",
    "del(X_valid_eo_aug)\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "a7b666b8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ebe43ae06a4d4cc295acc2a161ba4197",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/204800 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test data feature shape for EO condition:  (1600, 4480)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "6231"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_features_eo = get_features(X_test_eo_aug)\n",
    "\n",
    "print(\"Test data feature shape for EO condition: \", test_features_eo.shape)\n",
    "\n",
    "del(X_test_eo_aug)\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "631c7961",
   "metadata": {},
   "source": [
    "# Saving Extracted features for further training with AutoML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "e16bf6a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eyes closed Training target shape: (9180, 1)\n",
      "Eyes closed Validation target shape: (1620, 1)\n",
      "\n",
      "\n",
      "Eyes open Training target shape: (4080, 1)\n",
      "Eyes open Validation target shape: (720, 1)\n"
     ]
    }
   ],
   "source": [
    "Y_train_ec = np.expand_dims(Y_train_ec_aug, axis=1)\n",
    "Y_valid_ec = np.expand_dims(Y_valid_ec_aug, axis=1)\n",
    "\n",
    "Y_train_eo = np.expand_dims(Y_train_eo_aug, axis=1)\n",
    "Y_valid_eo = np.expand_dims(Y_valid_eo_aug, axis=1)\n",
    "\n",
    "print(\"Eyes closed Training target shape:\", Y_train_ec.shape)\n",
    "print(\"Eyes closed Validation target shape:\", Y_valid_ec.shape)\n",
    "print(\"\\n\")\n",
    "print(\"Eyes open Training target shape:\", Y_train_eo.shape)\n",
    "print(\"Eyes open Validation target shape:\", Y_valid_eo.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17e92225",
   "metadata": {},
   "source": [
    "### Saving for EC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "11aa87c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final training data shape for EC condition:  (9180, 4481)\n",
      "Final validation data shape for EC condition:  (9180, 4481)\n"
     ]
    }
   ],
   "source": [
    "df_train_ec = pd.DataFrame(data=np.hstack((train_features_ec, Y_train_ec)), index=None, columns=None)\n",
    "df_valid_ec = pd.DataFrame(data=np.hstack((valid_features_ec, Y_valid_ec)), index=None, columns=None)\n",
    "\n",
    "df_train_ec.to_csv('exp4/ec/df_train_ec.csv', index=False)\n",
    "df_valid_ec.to_csv('exp4/ec/df_valid_ec.csv', index=False)\n",
    "\n",
    "print(\"Final training data shape for EC condition: \", df_train_ec.shape)\n",
    "print(\"Final validation data shape for EC condition: \", df_train_ec.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "ca2a4eb3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving test data features EC condition:  (3600, 4480)\n"
     ]
    }
   ],
   "source": [
    "print(\"Saving test data features EC condition: \", test_features_ec.shape)\n",
    "\n",
    "with open('exp4/ec/test_ec.npy', 'wb') as f:\n",
    "    np.save(f, test_features_ec)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "768867f3",
   "metadata": {},
   "source": [
    "### Saving for EO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "31852b88",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final training data shape for EO condition:  (4080, 4481)\n",
      "Final validation data shape for EO condition:  (4080, 4481)\n"
     ]
    }
   ],
   "source": [
    "df_train_eo = pd.DataFrame(data=np.hstack((train_features_eo, Y_train_eo)), index=None, columns=None)\n",
    "df_valid_eo = pd.DataFrame(data=np.hstack((valid_features_eo, Y_valid_eo)), index=None, columns=None)\n",
    "\n",
    "df_train_eo.to_csv('exp4/eo/df_train_eo.csv', index=False)\n",
    "df_valid_eo.to_csv('exp4/eo/df_valid_eo.csv', index=False)\n",
    "\n",
    "print(\"Final training data shape for EO condition: \", df_train_eo.shape)\n",
    "print(\"Final validation data shape for EO condition: \", df_train_eo.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "d3af64eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving test data features EO condition:  (1600, 4480)\n"
     ]
    }
   ],
   "source": [
    "print(\"Saving test data features EO condition: \", test_features_eo.shape)\n",
    "\n",
    "with open('exp4/eo/test_eo.npy', 'wb') as f:\n",
    "    np.save(f, test_features_eo)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c5b0980",
   "metadata": {},
   "source": [
    "### Saving Feature Extraction Info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "e09767e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('exp4/feature_extraction_info.json', 'w') as f:\n",
    "    json.dump(feature_extraction_info, f, sort_keys = True, indent = 4, ensure_ascii = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d16d023",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8 - AzureML",
   "language": "python",
   "name": "python38-azureml"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

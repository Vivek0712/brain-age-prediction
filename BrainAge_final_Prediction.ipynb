{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "608b5617",
   "metadata": {},
   "source": [
    "# Imports & Loads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9666301a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import joblib\n",
    "import json\n",
    "from zipfile import ZipFile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "edb26404",
   "metadata": {},
   "outputs": [],
   "source": [
    "exps = [\"exp1\",\"exp2\",\"exp3\",\"exp4\", \"exp5\"]\n",
    "models = dict()\n",
    "\n",
    "for key in exps:\n",
    "    models[key] = {}\n",
    "    path = key+\"/feature_extraction_info.json\"\n",
    "    with open(path, 'r') as f:\n",
    "        feature_extraction_info = json.load(f)\n",
    "    \n",
    "    models[key][\"features\"] = feature_extraction_info\n",
    "    \n",
    "    for condition in [\"ec\", \"eo\"]:\n",
    "        test_features_condition_path = key + \"/\" + condition + \"/test_\"+condition+\".npy\"\n",
    "        models[key][condition] = {}\n",
    "        models[key][condition][\"path\"] = test_features_condition_path\n",
    "        test_features = np.load(test_features_condition_path, allow_pickle=True)\n",
    "        \n",
    "        models[key][condition][\"test\"] = {}\n",
    "        models[key][condition][\"test\"][\"features\"] = test_features\n",
    "        \n",
    "        \n",
    "        df_valid_path = key + \"/\" + condition + \"/df_valid_\"+condition+\".csv\"\n",
    "        df_valid = pd.read_csv(df_valid_path,index_col=False)\n",
    "        \n",
    "        models[key][condition][\"valid\"] = {}\n",
    "        \n",
    "        models[key][condition][\"valid\"][\"features\"] = df_valid\n",
    "        \n",
    "        models[key][condition][\"model\"] = {}\n",
    "        model_path = key + \"/\" + condition + \"/model.pkl\"\n",
    "        model_ec = joblib.load(model_path)\n",
    "        models[key][condition][\"model\"][\"file\"] = model_ec\n",
    "        models[key][condition][\"model\"][\"score\"] = 0.0\n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4923d43d",
   "metadata": {},
   "source": [
    "### Some required info from the feature extraction process"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ce54ea5",
   "metadata": {},
   "source": [
    "# Defining EO-EC models ensemble weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8184e675",
   "metadata": {},
   "outputs": [],
   "source": [
    "ec_model_weight = 0.635\n",
    "\n",
    "eo_model_weight = 0.365\n",
    "\n",
    "assert (ec_model_weight + eo_model_weight == 1), \"Sum of weights should be equal to 1\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f0b1cc2",
   "metadata": {},
   "source": [
    "# Metric function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "08b6725e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_MAE(signal1, signal2):\n",
    "    \n",
    "    \"\"\"\n",
    "    Returns the Mean Absoluete Error between signal1 and signal2 (Both should be 1d arrays)\n",
    "    \"\"\"\n",
    "    \n",
    "    return np.mean(np.abs(signal1 - signal2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88e104fa",
   "metadata": {},
   "source": [
    "# Verifying validation scores "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55defb8c",
   "metadata": {},
   "source": [
    "### EC Condition Validation set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "013e7ee2",
   "metadata": {},
   "outputs": [],
   "source": [
    "exps = [\"exp1\",\"exp2\",\"exp3\",\"exp4\", \"exp5\"]\n",
    "for key in exps:\n",
    "    for condition in [\"ec\", \"eo\"]:\n",
    "        valid_features = models[key][condition][\"valid\"][\"features\"]\n",
    "        model = models[key][condition][\"model\"][\"file\"]\n",
    "        valid_X = valid_features.iloc[:, :-1].to_numpy()\n",
    "        valid_Y = valid_features.iloc[:, -1].to_numpy()\n",
    "        valid_pred = model.predict(valid_X)\n",
    "        models[key][condition][\"pred\"] = valid_pred\n",
    "        model_valid_score = calc_MAE(valid_pred, valid_Y)\n",
    "        models[key][condition][\"model\"][\"score\"] = model_valid_score\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "6682671b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_eo_pred = pd.DataFrame()\n",
    "df_ec_pred = pd.DataFrame()\n",
    "for condition in [\"ec\", \"eo\"]:\n",
    "    for key in exps:\n",
    "        if condition == \"ec\":\n",
    "            df_ec_pred[key] = models[key][condition][\"pred\"]\n",
    "        else:\n",
    "            df_eo_pred[key] = models[key][condition][\"pred\"]\n",
    "            \n",
    "df_eo_pred['mean'] = df_eo_pred.mean(axis=1)\n",
    "df_ec_pred['mean'] = df_ec_pred.mean(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "beb20279",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_valid_subjects = models[\"exp1\"][\"features\"]['n_subjects_valid']\n",
    "n_test_subjects = models[\"exp1\"][\"features\"]['n_subjects_test']\n",
    "\n",
    "n_windows_ec = models[\"exp1\"][\"features\"]['n_windows_ec']\n",
    "n_windows_eo = models[\"exp1\"][\"features\"]['n_windows_eo']\n",
    "\n",
    "test_subjects = models[\"exp1\"][\"features\"]['test_dataset_subjects']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "c549032b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation set final score:  1.563383140119739\n"
     ]
    }
   ],
   "source": [
    "valid_Y_actual = valid_Y[::n_windows_eo]\n",
    "valid_ec_Y_pred = df_ec_pred['mean'].to_numpy().reshape(n_valid_subjects, -1)\n",
    "valid_ec_Y_pred = np.mean(valid_ec_Y_pred, axis=1)\n",
    "\n",
    "valid_eo_Y_pred = df_eo_pred['mean'].to_numpy().reshape(n_valid_subjects, -1)\n",
    "valid_eo_Y_pred = np.mean(valid_eo_Y_pred, axis=1)\n",
    "\n",
    "valid_Y_pred = (ec_model_weight*valid_ec_Y_pred) + (eo_model_weight*valid_eo_Y_pred)\n",
    "\n",
    "final_validation_score = calc_MAE(valid_Y_pred, valid_Y_actual)\n",
    "print(\"Validation set final score: \", final_validation_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "d7c1afa2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1600, 4480)\n",
      "0   9.76\n",
      "1   8.71\n",
      "2   9.02\n",
      "3   9.83\n",
      "4   9.36\n",
      "Name: mean, dtype: float64\n",
      "       id   age\n",
      "0    1601  9.03\n",
      "1    1602  9.93\n",
      "2    1603  9.97\n",
      "3    1604 10.09\n",
      "4    1605  8.18\n",
      "..    ...   ...\n",
      "395  1996  7.49\n",
      "396  1997 13.15\n",
      "397  1998  7.62\n",
      "398  1999  8.35\n",
      "399  2000 11.25\n",
      "\n",
      "[400 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "test_features  =  models[key][condition][\"test\"][\"features\"]\n",
    "print(test_features.shape)\n",
    "df_eo_test_pred = pd.DataFrame()\n",
    "df_ec_test_pred = pd.DataFrame()\n",
    "for condition in [\"ec\", \"eo\"]:\n",
    "    for key in exps:\n",
    "        if condition == \"ec\":\n",
    "            model = models[key][condition][\"model\"][\"file\"]\n",
    "            test_pred = model.predict(test_features)\n",
    "            models[key][condition][\"test\"][\"pred\"] = test_pred\n",
    "            df_ec_test_pred[key] =  test_pred\n",
    "            \n",
    "        else:\n",
    "            model = models[key][condition][\"model\"][\"file\"]\n",
    "            test_pred = model.predict(test_features)\n",
    "            \n",
    "            models[key][condition][\"test\"][\"pred\"] = test_pred\n",
    "            df_eo_test_pred[key] =  test_pred\n",
    "            \n",
    "            \n",
    "df_eo_test_pred['mean'] = df_eo_test_pred.mean(axis=1)\n",
    "df_ec_test_pred['mean'] = df_ec_test_pred.mean(axis=1)\n",
    "print(df_eo_test_pred['mean'].head())\n",
    "\n",
    "\n",
    "\n",
    "test_eo_pred = df_eo_test_pred['mean'].to_numpy().reshape(n_test_subjects, -1)\n",
    "test_eo_pred = np.mean(test_eo_pred, axis=1)\n",
    "\n",
    "test_ec_pred = df_ec_test_pred['mean'].to_numpy().reshape(n_test_subjects, -1)\n",
    "test_ec_pred = np.mean(test_ec_pred, axis=1)\n",
    "\n",
    "\n",
    "test_preds_final = (ec_model_weight*test_ec_pred) + (eo_model_weight*test_eo_pred)\n",
    "\n",
    "df_final = pd.DataFrame({\"id\":test_subjects, \"age\":test_preds_final})\n",
    "\n",
    "df_final.to_csv(\"df_split_submission.csv\", index=False)\n",
    "\n",
    "print(df_final)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "0c42a9e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "with ZipFile(\"df_split_submission.zip\", 'w') as zipf:\n",
    "    zipf.write(\"df_split_submission.csv\", arcname=\"df_split_submission.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8bed8e3",
   "metadata": {},
   "source": [
    "### EO Condition validation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "f378dec4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "autoML_model_eo validation set score:  1.8187050114823526\n"
     ]
    }
   ],
   "source": [
    "valid_eo_features = df_valid_eo.iloc[:, :-1].to_numpy()\n",
    "valid_eo_Y = df_valid_eo.iloc[:, -1].to_numpy()\n",
    "\n",
    "valid_eo_pred = model_eo.predict(valid_eo_features)\n",
    "\n",
    "model_eo_valid_score = calc_MAE(valid_eo_pred, valid_eo_Y)\n",
    "print(\"autoML_model_eo validation set score: \", model_eo_valid_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ec4d30f",
   "metadata": {},
   "source": [
    "### Ensemble score over Validation set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "81974e30",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Actual age values are same for both 'eo' and 'ec' validation sets\n",
    "\n",
    "valid_Y_actual = valid_ec_Y[::n_windows_ec]\n",
    "\n",
    "#valid_Y_actual = validY_eo[::n_windows_eo] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "40f9063f",
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_ec_Y_pred = valid_ec_pred.reshape(n_valid_subjects, -1)\n",
    "valid_ec_Y_pred = np.mean(valid_ec_Y_pred, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "3520997f",
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_eo_Y_pred = valid_eo_pred.reshape(n_valid_subjects, -1)\n",
    "valid_eo_Y_pred = np.mean(valid_eo_Y_pred, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "98109044",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation set final score:  1.5787076303198\n"
     ]
    }
   ],
   "source": [
    "valid_Y_pred = (ec_model_weight*valid_ec_Y_pred) + (eo_model_weight*valid_eo_Y_pred)\n",
    "\n",
    "final_validation_score = calc_MAE(valid_Y_pred, valid_Y_actual)\n",
    "print(\"Validation set final score: \", final_validation_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d47a76c5",
   "metadata": {},
   "source": [
    "# Test Predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1dc3516c",
   "metadata": {},
   "source": [
    "### model_ec prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "70b0f001",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_ec_pred = model_ec.predict(test_features_ec)\n",
    "\n",
    "test_ec_pred = test_ec_pred.reshape(n_test_subjects, -1)\n",
    "\n",
    "test_ec_pred = np.mean(test_ec_pred, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44659b9e",
   "metadata": {},
   "source": [
    "### model_eo prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "58ab1202",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_eo_pred = model_eo.predict(test_features_eo)\n",
    "\n",
    "test_eo_pred = test_eo_pred.reshape(n_test_subjects, -1)\n",
    "\n",
    "test_eo_pred = np.mean(test_eo_pred, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "023fecaa",
   "metadata": {},
   "source": [
    "### Ensemble of 'eo' and 'ec' predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "523aebc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_preds_final = (ec_model_weight*test_ec_pred) + (eo_model_weight*test_eo_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f84eb36",
   "metadata": {},
   "source": [
    "### Saving the predictions in a dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "23e8832b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       id   age\n",
      "0    1601  9.20\n",
      "1    1602  9.67\n",
      "2    1603 10.31\n",
      "3    1604 10.51\n",
      "4    1605  8.57\n",
      "..    ...   ...\n",
      "395  1996  7.40\n",
      "396  1997 12.69\n",
      "397  1998  7.20\n",
      "398  1999  9.60\n",
      "399  2000 10.99\n",
      "\n",
      "[400 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "df_final = pd.DataFrame({\"id\":test_subjects, \"age\":test_preds_final})\n",
    "\n",
    "df_final.to_csv(\"df_submission.csv\", index=False)\n",
    "\n",
    "print(df_final)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca04e86b",
   "metadata": {},
   "source": [
    "### Zipping the submission dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b767c8f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "with ZipFile(\"df_submission.zip\", 'w') as zipf:\n",
    "    zipf.write(\"df_submission.csv\", arcname=\"df_submission.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
